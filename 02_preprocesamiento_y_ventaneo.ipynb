{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5867fe9f",
      "metadata": {
        "id": "5867fe9f"
      },
      "source": [
        "# **Preprocesamiento, limpieza, normalización y creación de ventanas para modelos secuenciales (CNN, LSTM, CNN-LSTM)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65087e04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65087e04",
        "outputId": "b75a47e9-c689-46b4-f1c6-39634e087b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Librerías cargadas y semilla fijada.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Importación de librerías y configuración global\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "print(\"Librerías cargadas y semilla fijada.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceb70967",
      "metadata": {
        "id": "ceb70967"
      },
      "source": [
        "Definimos las rutas usando Path, que funciona igual en Windows/Colab/Linux. No hay rutas absolutas que rompan el notebook. Luego leemos los tres archivos igual que en el Notebook 01, manteniendo consistencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7983f4b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7983f4b0",
        "outputId": "96a13d9d-fc2d-404b-a4a5-8501793f2be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets cargados correctamente:\n",
            "Etios: (272008, 47)\n",
            "Figo:  (167559, 47)\n",
            "RRV:   (0, 3)\n",
            "Datasets cargados correctamente.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CARGA AUTOMÁTICA DE DATOS DESDE GOOGLE DRIVE (SIN MONTAR)\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "url_etios = \"https://drive.google.com/uc?export=download&id=1FExXO0NzOWPCGeLVerHClndAMaASocSc\"\n",
        "url_figo  = \"https://drive.google.com/uc?export=download&id=10SvGG6Rj0xHwwO4bkutR3DY_wipxtBN7\"\n",
        "url_rrv   = \"https://drive.google.com/uc?export=download&id=1U-SjwjE3AfPpMGrhWVq-ecsQwNjVseO-\"\n",
        "\n",
        "etios = pd.read_csv(url_etios)\n",
        "figo  = pd.read_csv(url_figo)\n",
        "rrv   = pd.read_csv(url_rrv)\n",
        "\n",
        "print(\"Datasets cargados correctamente:\")\n",
        "print(\"Etios:\", etios.shape)\n",
        "print(\"Figo: \", figo.shape)\n",
        "print(\"RRV:  \", rrv.shape)\n",
        "\n",
        "print(\"Datasets cargados correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9395da1e",
      "metadata": {
        "id": "9395da1e"
      },
      "source": [
        "### Unificación en un solo dataset\n",
        "\n",
        "Esto es normal en proyectos de series temporales cuando todos representan el mismo tipo de sistema físico. Se crea un solo dataframe para simplificar escalado y ventaneo. ignore_index=True evita conflictos de índices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4723aa0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4723aa0e",
        "outputId": "0099f214-ab1e-42c8-cdf0-aad0394ed86f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset unificado con forma: (439567, 50)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Unificación de datasets\n",
        "# ============================================================\n",
        "\n",
        "df = pd.concat([etios, figo, rrv], ignore_index=True)\n",
        "\n",
        "print(\"Dataset unificado con forma:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18d057d5",
      "metadata": {
        "id": "18d057d5"
      },
      "source": [
        "**Identificar variable objetivo NOx**: busca automáticamente la columna con NOx, independientemente de cómo se llame (NOX, nox_ppm, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0df57576",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0df57576",
        "outputId": "5e324ab3-2749-4ce4-bddb-4edc801197f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable objetivo detectada: NOx_wet_conc\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Detección automática del nombre de la columna objetivo (NOx)\n",
        "# ============================================================\n",
        "\n",
        "target_col = None\n",
        "for col in df.columns:\n",
        "    if \"nox\" in col.lower():\n",
        "        target_col = col\n",
        "        break\n",
        "\n",
        "print(\"Variable objetivo detectada:\", target_col)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00d103e5",
      "metadata": {
        "id": "00d103e5"
      },
      "source": [
        "**Selección de variables numéricas**: Escogemos todas las columnas numéricas como features iniciales. CNN y LSTM solo trabajan con datos numéricos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5bdfe97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5bdfe97",
        "outputId": "1ff1b7b7-7523-4a0c-f0a0-8dbbf28a63af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variables numéricas total: 45\n",
            "['trip', 'driver', 'route', 'load', 'gps_lat', 'gps_lon', 'gps_alt', 'gps_speed', 'humidity', 'pressure', 'temp', 'rpm', 'speed_vehicle', 'throttle', 'manifold_pressure', 'manifold_temp', 'coolant_temp', 'fuel_flow', 'fuel_rate', 'air_fuel_ratio', 'exh_humidity', 'exh_mass_flow', 'exh_flow_scfm', 'exh_flow_ls', 'exh_temp', 'CO2_amb_conc', 'CO_amb_conc', 'NO_amb_conc', 'NO2_amb_conc', 'O2_amb_conc', 'CO2_wet_conc', 'CO_wet_conc', 'NO_wet_conc', 'NO2_wet_conc', 'NOx_wet_conc', 'O2_wet_conc', 'CO2_mass', 'CO_mass', 'NO_mass', 'NO2_mass', 'NOx_mass', 'O2_mass', 'NO_mass_cor', 'NO2_mass_cor', 'NOx_mass_cor']\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Selección de variables numéricas para el modelo\n",
        "# ============================================================\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Asegurarnos de que la variable objetivo está incluida\n",
        "assert target_col in numeric_cols, \"NOx no es numérica, revisar CSV.\"\n",
        "\n",
        "print(\"Variables numéricas total:\", len(numeric_cols))\n",
        "print(numeric_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "829ebf25",
      "metadata": {
        "id": "829ebf25"
      },
      "source": [
        "**Tratamiento básico de NaNs**: Rellenamos valores faltantes propagando hacia adelante y atrás. Es un método muy común en series temporales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54ffdcdb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54ffdcdb",
        "outputId": "ffffdf91-cb0a-4df6-95f8-4a8e0b5720ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3311405938.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df[numeric_cols] = df[numeric_cols].fillna(method='ffill').fillna(method='bfill')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaNs tratados.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Limpieza inicial: manejo simple de NaN por forward-fill\n",
        "# ============================================================\n",
        "\n",
        "df[numeric_cols] = df[numeric_cols].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "print(\"NaNs tratados.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a6d203d",
      "metadata": {
        "id": "6a6d203d"
      },
      "source": [
        "**Separación: features (X) y objetivo (y)**: Creamos matrices independientes:\n",
        "\n",
        "X: todas las variables numéricas\n",
        "\n",
        "y: solo NOx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d944225e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d944225e",
        "outputId": "51e957bd-85e9-49d8-a5ba-eea5ecab0a79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (439567, 45)\n",
            "y shape: (439567,)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Separación de X e y\n",
        "# ============================================================\n",
        "\n",
        "X = df[numeric_cols].copy()\n",
        "y = df[target_col].copy()\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7d9328c",
      "metadata": {
        "id": "c7d9328c"
      },
      "source": [
        "**Split por trayectos (sin fuga temporal)**: para evitar que el modelo vea el futuro se hace un split temporal puro: el pasado → entrenamiento; el futuro → validación/test. Crucial para evitar “data leakage”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6760e845",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6760e845",
        "outputId": "1a04ea6e-7731-435b-dfa4-813d89472cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (263740, 45)\n",
            "Val:   (87913, 45)\n",
            "Test:  (87914, 45)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Split secuencial train/val/test (sin mezclado)\n",
        "# ============================================================\n",
        "\n",
        "n = len(df)\n",
        "train_end = int(0.6 * n)\n",
        "val_end   = int(0.8 * n)\n",
        "\n",
        "X_train = X.iloc[:train_end].values\n",
        "y_train = y.iloc[:train_end].values\n",
        "\n",
        "X_val   = X.iloc[train_end:val_end].values\n",
        "y_val   = y.iloc[train_end:val_end].values\n",
        "\n",
        "X_test  = X.iloc[val_end:].values\n",
        "y_test  = y.iloc[val_end:].values\n",
        "\n",
        "print(\"Train:\", X_train.shape)\n",
        "print(\"Val:  \", X_val.shape)\n",
        "print(\"Test: \", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29b32ad3",
      "metadata": {
        "id": "29b32ad3"
      },
      "source": [
        "**Normalización (solo se ajusta con train)**: se ajusta el escalador únicamente con el set de entrenamiento.\n",
        "Luego se aplica a val/test → buenas prácticas de ML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f7f046e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f7f046e",
        "outputId": "9461ac5a-7f3c-4b1b-ff9f-1960bfe778a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalización completada.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Normalización estándar: fit solo en train\n",
        "# ============================================================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_val_scaled   = scaler.transform(X_val)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "print(\"Normalización completada.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4550803d",
      "metadata": {
        "id": "4550803d"
      },
      "source": [
        "**Función para crear ventanas temporales**: Convierte una serie en muestras del tipo:\n",
        "\n",
        "[ t, t+1, ..., t+T ] → y en t+T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e035ead",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e035ead",
        "outputId": "1cd8aa2c-10d1-43f5-83e1-a5a4acbcdd49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Función create_windows definida.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Función de ventaneo (crea tensores para modelos secuenciales)\n",
        "# ============================================================\n",
        "\n",
        "def create_windows(X, y, window_size):\n",
        "    X_w, y_w = [], []\n",
        "    for i in range(len(X) - window_size):\n",
        "        X_w.append(X[i:i+window_size])\n",
        "        y_w.append(y[i+window_size])\n",
        "    return np.array(X_w), np.array(y_w)\n",
        "\n",
        "print(\"Función create_windows definida.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1828a8d",
      "metadata": {
        "id": "a1828a8d"
      },
      "source": [
        "float64 → float32 reduce memoria al 50%, acelera entrenamiento y evita errores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff8ae63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ff8ae63",
        "outputId": "aa89952a-0604-47e5-95ae-43f3d6664d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos convertidos a float32.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Conversión a float32 para reducir memoria a la mitad\n",
        "# ============================================================\n",
        "\n",
        "X_train_scaled = X_train_scaled.astype(np.float32)\n",
        "X_val_scaled   = X_val_scaled.astype(np.float32)\n",
        "X_test_scaled  = X_test_scaled.astype(np.float32)\n",
        "\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_val   = y_val.astype(np.float32)\n",
        "y_test  = y_test.astype(np.float32)\n",
        "\n",
        "print(\"Datos convertidos a float32.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62e50b9d",
      "metadata": {
        "id": "62e50b9d"
      },
      "source": [
        "Esta función:\n",
        "\n",
        "- No genera un arreglo gigante\n",
        "\n",
        "- Usa ventanas en streaming.\n",
        "\n",
        "- Permite batch automático.\n",
        "\n",
        "- Sirve para todos tus modelos secuenciales (CNN, LSTM, CNN-LSTM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e896824f",
      "metadata": {
        "id": "e896824f"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Creación correcta de ventanas en tf.data para pares (X, y)\n",
        "# ============================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def make_window_dataset(X, y, window, batch, shuffle=True):\n",
        "    \"\"\"\n",
        "    Construye un dataset de ventanas seguras para TensorFlow:\n",
        "    Entrada:\n",
        "        X: matriz numpy (n_samples, n_features)\n",
        "        y: vector numpy (n_samples,)\n",
        "    Salida:\n",
        "        Dataset con batches de shape:\n",
        "            X_batch: (batch, window, n_features)\n",
        "            y_batch: (batch,)\n",
        "    \"\"\"\n",
        "\n",
        "    # Datasets independientes\n",
        "    X_ds = tf.data.Dataset.from_tensor_slices(X)\n",
        "    y_ds = tf.data.Dataset.from_tensor_slices(y)\n",
        "\n",
        "    # Ventanas separadas para X e y\n",
        "    X_w = X_ds.window(window, shift=1, drop_remainder=True)\n",
        "    y_w = y_ds.window(window, shift=1, drop_remainder=True)\n",
        "\n",
        "    # Convertimos cada ventana en un batch real\n",
        "    X_w = X_w.flat_map(lambda w: w.batch(window))\n",
        "    y_w = y_w.flat_map(lambda w: w.batch(window))\n",
        "\n",
        "    # Emparejar ventanas X_window, y_window\n",
        "    ds = tf.data.Dataset.zip((X_w, y_w))\n",
        "\n",
        "    # Para cada ventana, dejamos:\n",
        "    #   X_window --> (window, n_features)\n",
        "    #   y_window --> tomamos el último valor como etiqueta\n",
        "    ds = ds.map(lambda x, y: (x, y[-1]))\n",
        "\n",
        "    # Opcional: shuffle solo en train\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(5000, seed=SEED)\n",
        "\n",
        "    # Batch final + prefetch\n",
        "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return ds\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e1873e7",
      "metadata": {
        "id": "1e1873e7"
      },
      "source": [
        "**Crear datasets listos para entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac8abf92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac8abf92",
        "outputId": "706e9fa3-63dc-4d15-ee77-9cfb76ee2c90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets creados correctamente.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Creación de datasets para train, val y test\n",
        "# ============================================================\n",
        "\n",
        "WINDOW = 30\n",
        "BATCH  = 64\n",
        "\n",
        "train_ds = make_window_dataset(X_train_scaled, y_train, window=WINDOW, batch=BATCH, shuffle=True)\n",
        "val_ds   = make_window_dataset(X_val_scaled,   y_val,   window=WINDOW, batch=BATCH, shuffle=False)\n",
        "test_ds  = make_window_dataset(X_test_scaled,  y_test,  window=WINDOW, batch=BATCH, shuffle=False)\n",
        "\n",
        "print(\"Datasets creados correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c267572",
      "metadata": {
        "id": "9c267572"
      },
      "source": [
        "**Revisión rápida del shape (para confirmar)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21b21b13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21b21b13",
        "outputId": "ac8d1a7f-dd12-4f9b-f738-7936a9186b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch X: (64, 30, 45)\n",
            "Batch y: (64,)\n"
          ]
        }
      ],
      "source": [
        "for Xb, yb in train_ds.take(1):\n",
        "    print(\"Batch X:\", Xb.shape)  # (batch, window, n_features)\n",
        "    print(\"Batch y:\", yb.shape)  # (batch,)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c6837a",
      "metadata": {
        "id": "a6c6837a"
      },
      "source": [
        "**Guardar metadatos del preprocesamiento**:\n",
        "Guardamos solo lo necesario para reconstruir el pipeline en Colab o en inferencia:\n",
        "\n",
        "- Escalador\n",
        "\n",
        "- Columnas\n",
        "\n",
        "- Tamaño de ventana\n",
        "\n",
        "- Sin ocupar RAM innecesaria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d229ab36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d229ab36",
        "outputId": "d01c4728-7a30-4146-e0f0-f89fd7641ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing_info.json guardado correctamente.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Guardar metadatos del preprocesamiento\n",
        "# ============================================================\n",
        "\n",
        "preprocessing_info = {\n",
        "    \"feature_names\": numeric_cols,\n",
        "    \"target\": target_col,\n",
        "    \"window\": WINDOW,\n",
        "    \"scaler_mean\": scaler.mean_.tolist(),\n",
        "    \"scaler_scale\": scaler.scale_.tolist(),\n",
        "}\n",
        "\n",
        "import json\n",
        "with open(\"preprocessing_info.json\", \"w\") as f:\n",
        "    json.dump(preprocessing_info, f, indent=4)\n",
        "\n",
        "print(\"preprocessing_info.json guardado correctamente.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eedd6cdc",
      "metadata": {
        "id": "eedd6cdc"
      },
      "source": [
        "**Guardar splits (solo escalados)**:\n",
        "\n",
        "Aunque usamos tf.data para ventaneo, es útil guardar los splits escalados para reproducibilidad o para crear ventanas distintas (ej. T=60 luego)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "670fe16c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "670fe16c",
        "outputId": "b9d31096-5a54-41e5-e253-13c00788cb1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "splits_escalados.npz guardado correctamente.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Guardar los splits escalados para futuros notebooks\n",
        "# ============================================================\n",
        "\n",
        "np.savez(\"splits_escalados.npz\",\n",
        "         X_train=X_train_scaled,\n",
        "         y_train=y_train,\n",
        "         X_val=X_val_scaled,\n",
        "         y_val=y_val,\n",
        "         X_test=X_test_scaled,\n",
        "         y_test=y_test)\n",
        "\n",
        "print(\"splits_escalados.npz guardado correctamente.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed80806",
      "metadata": {
        "id": "eed80806"
      },
      "source": [
        "**Inspección rápida del dataset final**\n",
        "\n",
        "Para asegurarnos de que todo funciona, añadimos una celda que imprime shapes y ejemplos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9840c7ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9840c7ca",
        "outputId": "6504a43f-4fb7-4789-e795-46464790d85c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes originales:\n",
            "  X_train: (263740, 45)\n",
            "  X_val:   (87913, 45)\n",
            "  X_test:  (87914, 45)\n",
            "\n",
            "Ejemplo batch X: (64, 30, 45)\n",
            "Ejemplo batch y: (64,)\n",
            "\n",
            "Todo listo para usar en modelos CNN, LSTM y CNN-LSTM.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Validación final del preprocesamiento\n",
        "# ============================================================\n",
        "\n",
        "print(\"Shapes originales:\")\n",
        "print(\"  X_train:\", X_train_scaled.shape)\n",
        "print(\"  X_val:  \", X_val_scaled.shape)\n",
        "print(\"  X_test: \", X_test_scaled.shape)\n",
        "print()\n",
        "\n",
        "# Probar batch real\n",
        "for Xb, yb in train_ds.take(1):\n",
        "    print(\"Ejemplo batch X:\", Xb.shape)\n",
        "    print(\"Ejemplo batch y:\", yb.shape)\n",
        "    break\n",
        "\n",
        "print(\"\\nTodo listo para usar en modelos CNN, LSTM y CNN-LSTM.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ece923e",
      "metadata": {
        "id": "8ece923e"
      },
      "source": [
        "\n",
        "# **Conclusión del notebook**\n",
        "\n",
        "\n",
        "En este notebook se completó el preprocesamiento integral del conjunto de datos, garantizando un pipeline reproducible y compatible con modelos secuenciales de Deep Learning. Se unificaron y limpiaron los registros, se manejaron adecuadamente valores faltantes, y se aplicó una normalización estricta sin fuga de información. Los datos se dividieron temporalmente en conjuntos de entrenamiento, validación y prueba, y se implementó un sistema de ventaneo eficiente mediante tf.data, capaz de generar secuencias para CNN, LSTM y arquitecturas híbridas sin comprometer la memoria. Finalmente, se guardaron los metadatos y splits necesarios para asegurar continuidad en los siguientes notebooks. Con esto, el dataset queda completamente preparado para iniciar el desarrollo y evaluación de los modelos de Deep Learning.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}